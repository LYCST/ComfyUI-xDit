"""
xDiT Ray Worker
==============

Ray Actor for GPU-specific inference operations.
"""

import os
import sys
import torch
import logging
import time
import datetime
from typing import Dict, Any, Optional, List, Tuple
import numpy as np
import threading
import socket
import signal

# ðŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿Ray workerèƒ½æ‰¾åˆ°ComfyUIæ¨¡å—
# æ·»åŠ ComfyUIæ ¹ç›®å½•åˆ°Pythonè·¯å¾„
comfyui_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
if comfyui_root not in sys.path:
    sys.path.insert(0, comfyui_root)

# æ·»åŠ custom_nodesç›®å½•åˆ°Pythonè·¯å¾„
custom_nodes_path = os.path.join(comfyui_root, 'custom_nodes')
if custom_nodes_path not in sys.path:
    sys.path.insert(0, custom_nodes_path)

# çŽ°åœ¨å¯ä»¥æ­£ç¡®å¯¼å…¥ComfyUIæ¨¡å—
try:
    import folder_paths
    import comfy.sd
    import comfy.utils
    COMFYUI_AVAILABLE = True
except ImportError:
    COMFYUI_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("ComfyUI modules not available in worker")

# Try to import Ray
try:
    import ray
    RAY_AVAILABLE = True
except ImportError:
    RAY_AVAILABLE = False

# Try to import xDiT with correct API
try:
    import xfuser
    from xfuser import xFuserArgs
    from xfuser.core.distributed import get_world_group
    # Import FLUX specific pipeline and config
    from xfuser import xFuserFluxPipeline
    from xfuser.config.config import EngineConfig
    XDIT_AVAILABLE = True
except ImportError:
    XDIT_AVAILABLE = False

logger = logging.getLogger(__name__)

def find_free_port():
    """Find a free port for distributed communication"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.bind(('', 0))
        s.listen(1)
        port = s.getsockname()[1]
    return port



@ray.remote(num_gpus=1) if RAY_AVAILABLE else None
class XDiTWorker:
    """
    Ray Actor for GPU-specific xDiT operations.
    Each worker is assigned to one GPU.
    """
    
    def __init__(self, gpu_id: int, model_path: str, strategy: str = "Hybrid", 
                 master_addr: str = "127.0.0.1", master_port: int = 29500, 
                 world_size: int = 8, rank: int = 0):
        self.gpu_id = gpu_id
        self.model_path = model_path
        self.strategy = strategy
        self.model_wrapper = None
        self.is_initialized = False
        self.world_size = world_size
        self.rank = rank
        self.master_addr = master_addr
        self.master_port = master_port
        self.distributed_initialized = False
        
        # è®¾ç½®è¯¦ç»†çš„æ—¥å¿—çº§åˆ«
        logging.getLogger("xfuser").setLevel(logging.DEBUG)
        logging.getLogger("torch.distributed").setLevel(logging.DEBUG)
        
        # è®¾ç½®GPUè®¾å¤‡
        try:
            # åœ¨RayçŽ¯å¢ƒä¸­è®¾ç½®CUDAè®¾å¤‡
            if RAY_AVAILABLE:
                # Rayä¼šè‡ªåŠ¨è®¾ç½®CUDA_VISIBLE_DEVICES
                self.device = f"cuda:{0}"  # åœ¨Rayä¸­æ€»æ˜¯0
                torch.cuda.set_device(0)
            else:
                # éžRayçŽ¯å¢ƒä¸‹æ‰‹åŠ¨è®¾ç½®
                os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)
                self.device = f"cuda:{0}"
                torch.cuda.set_device(0)
                
            logger.info(f"Worker initialized on GPU {gpu_id} (device={self.device}, rank={rank})")
            
        except Exception as e:
            logger.error(f"Failed to set GPU device for worker {gpu_id}: {e}")
            raise
    
    def initialize(self) -> bool:
        """Initialize the worker"""
        try:
            if not XDIT_AVAILABLE:
                logger.error(f"xDiT not available on GPU {self.gpu_id}")
                return False
            
            logger.info(f"Initializing worker on GPU {self.gpu_id} with strategy: {self.strategy}")
            
            # éªŒè¯GPUå¯ç”¨æ€§
            if not torch.cuda.is_available():
                logger.error(f"CUDA not available for worker on GPU {self.gpu_id}")
                return False
            
            # éªŒè¯å½“å‰è®¾å¤‡
            current_device = torch.cuda.current_device()
            logger.info(f"Current CUDA device for GPU {self.gpu_id}: {current_device}")
            
            # æ ‡è®°åˆå§‹åŒ–å®Œæˆ
            self.is_initialized = True
            logger.info(f"âœ… Worker on GPU {self.gpu_id} initialized")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize worker on GPU {self.gpu_id}: {e}")
            logger.exception("Full traceback:")
            return False
    
    def initialize_distributed(self) -> bool:
        """Initialize distributed environment - called after all workers are ready"""
        if self.distributed_initialized:
            return True
            
        try:
            logger.info(f"[GPU {self.gpu_id}] Initializing distributed environment...")
            
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§è¿›ç¨‹ç»„
            if torch.distributed.is_initialized():
                try:
                    torch.distributed.destroy_process_group()
                    logger.info(f"[GPU {self.gpu_id}] Destroyed existing process group")
                except Exception as e:
                    logger.warning(f"Error destroying process group: {e}")
            
            # è®¾ç½®åˆ†å¸ƒå¼çŽ¯å¢ƒå˜é‡
            os.environ['MASTER_ADDR'] = self.master_addr
            os.environ['MASTER_PORT'] = str(self.master_port)
            os.environ['WORLD_SIZE'] = str(self.world_size)
            os.environ['RANK'] = str(self.rank)
            os.environ['LOCAL_RANK'] = '0'  # Rayä¸­æ¯ä¸ªworkeréƒ½æ˜¯local rank 0
            os.environ['NCCL_DEBUG'] = 'INFO'  # å¯ç”¨NCCLè°ƒè¯•
            
            logger.info(f"[GPU {self.gpu_id}] Distributed env: MASTER={self.master_addr}:{self.master_port}, "
                       f"WORLD_SIZE={self.world_size}, RANK={self.rank}")
            
            # åˆå§‹åŒ–åˆ†å¸ƒå¼çŽ¯å¢ƒ
            torch.distributed.init_process_group(
                backend='nccl',
                init_method=f'tcp://{self.master_addr}:{self.master_port}',
                world_size=self.world_size,
                rank=self.rank,
                timeout=datetime.timedelta(minutes=10)  # å¢žåŠ è¶…æ—¶æ—¶é—´
            )
            
            # éªŒè¯åˆ†å¸ƒå¼åˆå§‹åŒ–
            if torch.distributed.is_initialized():
                world_size = torch.distributed.get_world_size()
                rank = torch.distributed.get_rank()
                logger.info(f"[GPU {self.gpu_id}] âœ… Distributed initialized: world_size={world_size}, rank={rank}")
                self.distributed_initialized = True
                return True
            else:
                logger.error(f"[GPU {self.gpu_id}] Distributed initialization failed")
                return False
                
        except Exception as e:
            logger.error(f"[GPU {self.gpu_id}] Failed to initialize distributed: {e}")
            logger.exception("Distributed init traceback:")
            self._cleanup_distributed()
            return False
    
    def _create_xfuser_pipeline_if_needed(self, model_path: str = None) -> bool:
        """åˆ›å»ºxfuser pipeline - ä½¿ç”¨xDiTçš„åŽŸå§‹æ–¹æ³•"""
        if self.model_wrapper is not None and self.model_wrapper != "deferred_loading":
            return True
            
        try:
            # ä½¿ç”¨ä¼ é€’çš„æ¨¡åž‹è·¯å¾„ï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            effective_model_path = model_path or self.model_path
            logger.info(f"[GPU {self.gpu_id}] Creating xfuser pipeline with path: {effective_model_path}")
            
            # ç¡®ä¿åˆ†å¸ƒå¼çŽ¯å¢ƒå·²åˆå§‹åŒ–
            if not self.distributed_initialized:
                logger.error(f"[GPU {self.gpu_id}] Distributed not initialized")
                return False
            
            # åˆ›å»ºpipeline - ä½¿ç”¨xDiTçš„åŽŸå§‹æ–¹æ³•
            try:
                # ç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                torch.cuda.set_device(0)  # Rayä¸­æ€»æ˜¯0
                
                # å¯¹äºŽsafetensorsæ–‡ä»¶ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                if effective_model_path.endswith('.safetensors'):
                    logger.info(f"[GPU {self.gpu_id}] Processing safetensors file")
                    
                    # æ–¹æ¡ˆ1ï¼šå°è¯•ä½¿ç”¨diffusersçš„from_single_file
                    try:
                        from diffusers import FluxPipeline
                        from xfuser import xFuserFluxPipeline
                        
                        logger.info(f"[GPU {self.gpu_id}] Trying to load safetensors with from_single_file")
                        
                        # ä½¿ç”¨from_single_fileåŠ è½½
                        pipeline = FluxPipeline.from_single_file(
                            effective_model_path,
                            torch_dtype=torch.bfloat16,
                            low_cpu_mem_usage=True
                        )
                        
                        # åˆ›å»ºxFuser wrapper
                        self.model_wrapper = xFuserFluxPipeline(pipeline, self.engine_config)
                        self.model_wrapper.to(self.device)
                        
                        logger.info(f"[GPU {self.gpu_id}] âœ… Successfully loaded safetensors with from_single_file")
                        return True
                        
                    except Exception as e:
                        logger.warning(f"[GPU {self.gpu_id}] from_single_file failed: {e}")
                        
                        # æ–¹æ¡ˆ2ï¼šåˆ›å»ºä¸´æ—¶diffusersç›®å½•
                        logger.info(f"[GPU {self.gpu_id}] Creating temporary diffusers directory")
                        
                        import json
                        import tempfile
                        import shutil
                        
                        temp_dir = f"/tmp/flux_diffusers_{self.gpu_id}_{os.getpid()}"
                        
                        try:
                            # æ¸…ç†æ—§çš„ä¸´æ—¶ç›®å½•
                            if os.path.exists(temp_dir):
                                shutil.rmtree(temp_dir)
                            
                            # åˆ›å»ºç›®å½•ç»“æž„
                            os.makedirs(temp_dir, exist_ok=True)
                            
                            # åˆ›å»ºmodel_index.json
                            model_index = {
                                "_class_name": "FluxPipeline",
                                "_diffusers_version": "0.30.0",
                                "scheduler": ["diffusers", "FlowMatchEulerDiscreteScheduler"],
                                "text_encoder": ["transformers", "CLIPTextModel"],
                                "text_encoder_2": ["transformers", "T5EncoderModel"],
                                "tokenizer": ["transformers", "CLIPTokenizer"],
                                "tokenizer_2": ["transformers", "T5TokenizerFast"],
                                "transformer": ["diffusers", "FluxTransformer2DModel"],
                                "vae": ["diffusers", "AutoencoderKL"]
                            }
                            
                            with open(os.path.join(temp_dir, "model_index.json"), "w") as f:
                                json.dump(model_index, f, indent=2)
                            
                            # åˆ›å»ºtransformerç›®å½•
                            transformer_dir = os.path.join(temp_dir, "transformer")
                            os.makedirs(transformer_dir, exist_ok=True)
                            
                            # å¤åˆ¶safetensorsæ–‡ä»¶
                            target_path = os.path.join(transformer_dir, "diffusion_pytorch_model.safetensors")
                            shutil.copy2(effective_model_path, target_path)
                            
                            # åˆ›å»ºconfig.json
                            transformer_config = {
                                "in_channels": 64,
                                "num_layers": 19,
                                "num_single_layers": 38,
                                "attention_head_dim": 128,
                                "num_attention_heads": 24,
                                "joint_attention_dim": 4096,
                                "pooled_projection_dim": 768,
                                "guidance_embeds": False
                            }
                            
                            with open(os.path.join(transformer_dir, "config.json"), "w") as f:
                                json.dump(transformer_config, f, indent=2)
                            
                            # ä½¿ç”¨ä¸´æ—¶ç›®å½•åˆ›å»ºpipeline
                            effective_model_path = temp_dir
                            logger.info(f"[GPU {self.gpu_id}] Created temporary diffusers directory at: {temp_dir}")
                            
                        except Exception as convert_error:
                            logger.error(f"[GPU {self.gpu_id}] Failed to create temp directory: {convert_error}")
                            return False
                
                # å¤„ç†diffusersç›®å½•
                if os.path.isdir(effective_model_path):
                    logger.info(f"[GPU {self.gpu_id}] Processing diffusers directory: {effective_model_path}")
                    
                    # éªŒè¯diffusersæ ¼å¼
                    model_index_path = os.path.join(effective_model_path, "model_index.json")
                    if not os.path.exists(model_index_path):
                        logger.error(f"[GPU {self.gpu_id}] Invalid diffusers directory: no model_index.json")
                        return False
                    
                    # ä½¿ç”¨xFuserArgsåˆ›å»ºå®Œæ•´é…ç½®
                    xfuser_args = xFuserArgs(
                        model=effective_model_path,
                        height=1024,
                        width=1024,
                        num_inference_steps=20,
                        guidance_scale=3.5,
                        output_type="latent",
                        tensor_parallel_degree=self.world_size,
                        use_ray=True,
                        ray_world_size=self.world_size
                    )
                    
                    engine_config = xfuser_args.create_config()
                    
                    # åˆ›å»ºpipeline
                    self.model_wrapper = xFuserFluxPipeline.from_pretrained(
                        effective_model_path,
                        engine_config=engine_config,
                        torch_dtype=torch.bfloat16,
                        low_cpu_mem_usage=True
                    )
                    
                    logger.info(f"[GPU {self.gpu_id}] âœ… Successfully loaded diffusers directory")
                    
                else:
                    logger.error(f"[GPU {self.gpu_id}] Unsupported model path format: {effective_model_path}")
                    return False
                
                # ç¡®ä¿æ¨¡åž‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                self.model_wrapper.to(self.device)
                
                logger.info(f"[GPU {self.gpu_id}] âœ… Pipeline created successfully!")
                return True
                
            except Exception as e:
                logger.error(f"[GPU {self.gpu_id}] Failed to create pipeline: {e}")
                logger.exception("Pipeline creation traceback:")
                return False
                
        except Exception as e:
            logger.error(f"[GPU {self.gpu_id}] Pipeline creation failed: {e}")
            logger.exception("Full traceback:")
            return False

    def _create_flux_pipeline_from_comfyui_components(self, model_info: Dict) -> bool:
        """ä»ŽComfyUIç»„ä»¶åˆ›å»ºFluxPipelineç”¨äºŽxDiTåŒ…è£…"""
        # è®¾ç½®è¶…æ—¶æœºåˆ¶
        timeout_seconds = 30  # 30ç§’è¶…æ—¶
        
        def timeout_handler(signum, frame):
            raise TimeoutError(f"Pipeline creation timed out after {timeout_seconds} seconds")
        
        # åœ¨Linuxä¸Šè®¾ç½®ä¿¡å·å¤„ç†å™¨
        try:
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(timeout_seconds)
        except (AttributeError, OSError):
            # Windowsä¸æ”¯æŒSIGALRMï¼Œä½¿ç”¨çº¿ç¨‹è¶…æ—¶
            pass
        
        try:
            logger.info(f"[GPU {self.gpu_id}] ðŸŽ¯ Creating FluxPipeline from ComfyUI components (timeout: {timeout_seconds}s)")
            
            # ðŸš€ å…³é”®æ´žå¯Ÿï¼šComfyUIå·²ç»æœ‰äº†æ‰€æœ‰å¿…è¦çš„ç»„ä»¶ï¼
            # æˆ‘ä»¬éœ€è¦åšçš„æ˜¯ï¼š
            # 1. åŠ è½½safetensorsä½œä¸ºtransformer
            # 2. ä»ŽComfyUIèŽ·å–å…¶ä»–ç»„ä»¶ï¼ˆVAE, CLIPç­‰ï¼‰
            # 3. ç»„è£…æˆdiffusersæ ¼å¼çš„FluxPipeline
            
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 1: Importing required modules...")
            from diffusers import FluxPipeline, FluxTransformer2DModel
            import torch
            import safetensors.torch
            
            # åŠ è½½safetensors transformeræƒé‡
            safetensors_path = model_info.get('path')
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 2: Loading transformer from: {safetensors_path}")
            
            custom_weights = safetensors.torch.load_file(safetensors_path)
            logger.info(f"[GPU {self.gpu_id}] âœ… Safetensors loaded, keys: {len(custom_weights)}")
            
            # åˆ›å»ºFluxTransformer2DModel
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 3: Creating FluxTransformer2DModel...")
            transformer = FluxTransformer2DModel(
                patch_size=1,
                in_channels=64,
                num_layers=19,
                num_single_layers=38,
                attention_head_dim=128,
                num_attention_heads=24,
                joint_attention_dim=4096,
                pooled_projection_dim=768,
                guidance_embeds=False,
                axes_dims_rope=(16, 56, 56)
            )
            
            # åŠ è½½è‡ªå®šä¹‰æƒé‡
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 4: Loading transformer weights...")
            missing_keys, unexpected_keys = transformer.load_state_dict(custom_weights, strict=False)
            logger.info(f"[GPU {self.gpu_id}] âœ… Transformer loaded: {len(missing_keys)} missing, {len(unexpected_keys)} unexpected")
            
            # ðŸŽ¯ æ–°ç­–ç•¥ï¼šç›´æŽ¥ä½¿ç”¨ComfyUIå·²åŠ è½½çš„ç»„ä»¶ï¼
            logger.info(f"[GPU {self.gpu_id}] ðŸ’¡ Smart strategy: Reusing ComfyUI loaded components")
            
            # ä»Žmodel_infoä¸­èŽ·å–ComfyUIå·²åŠ è½½çš„ç»„ä»¶
            comfyui_vae = model_info.get('vae')
            comfyui_clip = model_info.get('clip')
            
            if comfyui_vae is None or comfyui_clip is None:
                logger.warning(f"[GPU {self.gpu_id}] ComfyUI components not available in model_info")
                logger.info(f"[GPU {self.gpu_id}] Available keys: {list(model_info.keys())}")
                logger.info(f"[GPU {self.gpu_id}] VAE: {'âœ…' if comfyui_vae else 'âŒ'}, CLIP: {'âœ…' if comfyui_clip else 'âŒ'}")
                return False
            
            logger.info(f"[GPU {self.gpu_id}] âœ… Found ComfyUI loaded VAE and CLIP components")
            
            # ðŸŽ¯ å…³é”®ï¼šç›´æŽ¥è½¬æ¢ComfyUIç»„ä»¶ä¸ºdiffusersæ ¼å¼
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 5: Converting ComfyUI VAE to diffusers format...")
            logger.info(f"[GPU {self.gpu_id}] ComfyUI VAE type: {type(comfyui_vae)}")
            print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: VAE type = {type(comfyui_vae)}")  # å¼ºåˆ¶è¾“å‡º
            
            # ComfyUIçš„VAEé€šå¸¸æ˜¯comfy.model_management.VAEç±»åž‹
            # æˆ‘ä»¬éœ€è¦æå–å…¶å†…éƒ¨çš„diffusers VAE
            diffusers_vae = None
            vae_type_name = type(comfyui_vae).__name__
            logger.info(f"[GPU {self.gpu_id}] VAE type name: {vae_type_name}")
            print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: VAE type name = {vae_type_name}")  # å¼ºåˆ¶è¾“å‡º
            
            if hasattr(comfyui_vae, 'first_stage_model'):
                diffusers_vae = comfyui_vae.first_stage_model
                logger.info(f"[GPU {self.gpu_id}] âœ… Extracted first_stage_model")
                print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: Using first_stage_model")
            elif hasattr(comfyui_vae, 'model'):
                diffusers_vae = comfyui_vae.model
                logger.info(f"[GPU {self.gpu_id}] âœ… Extracted model")
                print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: Using model")
            elif 'AutoencodingEngine' in vae_type_name or hasattr(comfyui_vae, 'decoder'):
                # å¦‚æžœæ˜¯AutoencodingEngineç±»åž‹ï¼Œæˆ‘ä»¬éœ€è¦åŒ…è£…å®ƒ
                logger.info(f"[GPU {self.gpu_id}] ðŸ”§ Detected AutoencodingEngine - creating wrapper")
                print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: Creating VAE wrapper for {vae_type_name}")  # å¼ºåˆ¶è¾“å‡º
                
                # åˆ›å»ºä¸€ä¸ªä¸ŽFLUX VAEå…¼å®¹çš„config
                class VAEWrapper:
                    def __init__(self, autoencoding_engine):
                        self.autoencoding_engine = autoencoding_engine
                        # åˆ›å»ºä¸€ä¸ªä¸ŽFLUX VAEå…¼å®¹çš„config
                        self.config = type('Config', (), {
                            'block_out_channels': [128, 256, 512, 512],  # FLUX VAEé…ç½®
                            'in_channels': 3,
                            'out_channels': 3,
                            'latent_channels': 16,
                            'sample_size': 1024,  # FLUXé»˜è®¤å°ºå¯¸
                            'scaling_factor': 0.3611,  # FLUX VAE scaling factor
                            'shift_factor': 0.1159,   # FLUX VAE shift factor
                        })()
                        
                        # ç¡®ä¿åŒ…è£…å™¨æœ‰æ­£ç¡®çš„è®¾å¤‡å±žæ€§
                        self.device = getattr(autoencoding_engine, 'device', torch.device('cuda:0'))
                        self.dtype = getattr(autoencoding_engine, 'dtype', torch.bfloat16)
                    
                    def encode(self, x):
                        return self.autoencoding_engine.encode(x)
                    
                    def decode(self, x):
                        return self.autoencoding_engine.decode(x)
                    
                    def to(self, device):
                        # ç¡®ä¿è®¾å¤‡è½¬ç§»æ­£ç¡®ä¼ é€’
                        self.autoencoding_engine = self.autoencoding_engine.to(device)
                        self.device = device
                        return self
                    
                    @property
                    def parameters(self):
                        return self.autoencoding_engine.parameters()
                    
                    def __getattr__(self, name):
                        # å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬å®šä¹‰çš„å±žæ€§
                        if name in ['config', 'device', 'dtype']:
                            return object.__getattribute__(self, name)
                        # å¦åˆ™ä»Žautoencoding_engineèŽ·å–
                        return getattr(self.autoencoding_engine, name)
                
                diffusers_vae = VAEWrapper(comfyui_vae)
                logger.info(f"[GPU {self.gpu_id}] âœ… Created VAE wrapper with FLUX-compatible config")
                
                # éªŒè¯VAE wrapper
                if not hasattr(diffusers_vae, 'config'):
                    logger.error(f"[GPU {self.gpu_id}] VAE wrapper missing config attribute!")
                    return False
                
                logger.info(f"[GPU {self.gpu_id}] VAE config block_out_channels: {diffusers_vae.config.block_out_channels}")
                print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: VAE wrapper created successfully with config!")
            else:
                # å¦‚æžœæ— æ³•æå–ï¼Œè¿”å›žå¤±è´¥
                logger.error(f"[GPU {self.gpu_id}] Cannot extract diffusers VAE from ComfyUI VAE")
                logger.error(f"[GPU {self.gpu_id}] VAE type: {vae_type_name}")
                logger.error(f"[GPU {self.gpu_id}] Available attributes: {[attr for attr in dir(comfyui_vae) if not attr.startswith('_')]}")
                print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: VAE extraction failed!")
                return False
            
            print(f"ðŸ” [GPU {self.gpu_id}] DEBUG: Final VAE type = {type(diffusers_vae)}")
            logger.info(f"[GPU {self.gpu_id}] âœ… VAE component ready")
            
            # å°†ComfyUIçš„CLIPè½¬æ¢ä¸ºdiffusersæ ¼å¼
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 6: Converting ComfyUI CLIP to diffusers format...")
            logger.info(f"[GPU {self.gpu_id}] ComfyUI CLIP type: {type(comfyui_clip)}")
            
            # ComfyUIçš„CLIPå¯èƒ½åŒ…å«å¤šä¸ªtext encoder
            # å¯¹äºŽFLUXï¼Œæˆ‘ä»¬éœ€è¦CLIP-Lå’ŒT5-XXL
            text_encoder = None
            text_encoder_2 = None
            
            if hasattr(comfyui_clip, 'cond_stage_model'):
                # å°è¯•ä»ŽComfyUI CLIPä¸­æå–text encoder
                clip_model = comfyui_clip.cond_stage_model
                logger.info(f"[GPU {self.gpu_id}] Found cond_stage_model: {type(clip_model)}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªtext encoderï¼ˆFLUXéœ€è¦ä¸¤ä¸ªï¼‰
                if hasattr(clip_model, 'clip_l'):
                    text_encoder = clip_model.clip_l
                    logger.info(f"[GPU {self.gpu_id}] âœ… Found CLIP-L from ComfyUI")
                
                if hasattr(clip_model, 't5xxl'):
                    text_encoder_2 = clip_model.t5xxl
                    logger.info(f"[GPU {self.gpu_id}] âœ… Found T5-XXL from ComfyUI")
                
                # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–å±žæ€§
                if text_encoder is None and hasattr(clip_model, 'transformer'):
                    text_encoder = clip_model.transformer
                    logger.info(f"[GPU {self.gpu_id}] âœ… Found transformer as text_encoder")
                
                logger.info(f"[GPU {self.gpu_id}] Available clip_model attributes: {[attr for attr in dir(clip_model) if not attr.startswith('_')]}")
            
            # å¦‚æžœæ— æ³•ä»ŽComfyUIæå–å¿…è¦çš„text encodersï¼Œè¿”å›žå¤±è´¥
            if text_encoder is None or text_encoder_2 is None:
                logger.error(f"[GPU {self.gpu_id}] Missing text encoders from ComfyUI CLIP")
                logger.error(f"[GPU {self.gpu_id}] CLIP-L: {'âœ…' if text_encoder else 'âŒ'}, T5-XXL: {'âœ…' if text_encoder_2 else 'âŒ'}")
                return False
            
            # åˆ›å»ºç®€å•çš„tokenizerï¼ˆä¸éœ€è¦ä¸‹è½½ï¼‰
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 7: Creating lightweight tokenizers...")
            try:
                # ðŸ”§ ä¿®å¤tokenizeråˆ›å»ºé—®é¢˜ - åˆ›å»ºæœ€ç®€å•çš„tokenizeråŒ…è£…å™¨
                logger.info(f"[GPU {self.gpu_id}] Creating minimal tokenizer wrappers...")
                
                class MinimalTokenizer:
                    def __init__(self, vocab_size=49408, max_length=77):
                        self.vocab_size = vocab_size
                        self.model_max_length = max_length
                        self.pad_token_id = 0
                        self.eos_token_id = 2
                        self.bos_token_id = 1
                        self.unk_token_id = 3
                    
                    def __call__(self, text, **kwargs):
                        # è¿”å›žä¸€ä¸ªåŸºæœ¬çš„ç¼–ç ç»“æžœ
                        batch_size = 1 if isinstance(text, str) else len(text)
                        return {
                            'input_ids': torch.zeros((batch_size, self.model_max_length), dtype=torch.long),
                            'attention_mask': torch.ones((batch_size, self.model_max_length), dtype=torch.long)
                        }
                    
                    def encode(self, text, **kwargs):
                        return [0] * self.model_max_length
                    
                    def decode(self, token_ids, **kwargs):
                        return ""
                    
                    def batch_decode(self, sequences, **kwargs):
                        return [""] * len(sequences)
                
                # ä¸ºCLIPå’ŒT5åˆ›å»ºä¸åŒçš„tokenizer
                tokenizer = MinimalTokenizer(vocab_size=49408, max_length=77)  # CLIP tokenizer
                tokenizer_2 = MinimalTokenizer(vocab_size=32128, max_length=512)  # T5 tokenizer
                
                logger.info(f"[GPU {self.gpu_id}] âœ… Minimal tokenizer wrappers created successfully")
                
            except Exception as tokenizer_error:
                logger.error(f"[GPU {self.gpu_id}] Failed to create tokenizers: {tokenizer_error}")
                return False
            
            # åˆ›å»ºschedulerï¼ˆè½»é‡çº§ï¼‰
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 8: Creating scheduler...")
            try:
                from diffusers import FlowMatchEulerDiscreteScheduler
                scheduler = FlowMatchEulerDiscreteScheduler()
                logger.info(f"[GPU {self.gpu_id}] âœ… Scheduler created successfully")
            except Exception as scheduler_error:
                logger.error(f"[GPU {self.gpu_id}] Failed to create scheduler: {scheduler_error}")
                return False
            
            logger.info(f"[GPU {self.gpu_id}] âœ… All components ready for pipeline assembly")
            
            # ç»„è£…FluxPipeline
            logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 9: Assembling FluxPipeline...")
            try:
                pipeline = FluxPipeline(
                    transformer=transformer,
                    scheduler=scheduler,
                    vae=diffusers_vae,
                    text_encoder=text_encoder,
                    tokenizer=tokenizer,
                    text_encoder_2=text_encoder_2,
                    tokenizer_2=tokenizer_2,
                )
                
                logger.info(f"[GPU {self.gpu_id}] ðŸŽ‰ FluxPipeline created successfully using ComfyUI components!")
                
                # åˆ›å»ºxFuser wrapper
                logger.info(f"[GPU {self.gpu_id}] ðŸ“¥ Step 10: Creating xFuser wrapper...")
                from xfuser import xFuserFluxPipeline
                self.model_wrapper = xFuserFluxPipeline(pipeline, self.engine_config)
                
                logger.info(f"[GPU {self.gpu_id}] âœ… xFuser multi-GPU pipeline ready with ComfyUI components!")
                return True
                
            except Exception as pipeline_error:
                logger.error(f"[GPU {self.gpu_id}] Failed to create FluxPipeline: {pipeline_error}")
                logger.exception("Pipeline creation error:")
                return False
                
        except TimeoutError as e:
            logger.error(f"[GPU {self.gpu_id}] Pipeline creation timed out: {e}")
            return False
        except Exception as e:
            logger.error(f"[GPU {self.gpu_id}] Failed to create FluxPipeline from ComfyUI components: {e}")
            logger.exception("Component creation traceback:")
            return False
        finally:
            # æ¸…ç†è¶…æ—¶è®¾ç½®
            try:
                signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
            except (AttributeError, OSError):
                pass
    
    def _cleanup_distributed(self):
        """æ¸…ç†åˆ†å¸ƒå¼çŽ¯å¢ƒ"""
        try:
            if torch.distributed.is_initialized():
                torch.distributed.destroy_process_group()
                logger.info(f"[GPU {self.gpu_id}] Process group destroyed")
            
            # æ¸…ç†çŽ¯å¢ƒå˜é‡
            for var in ['MASTER_ADDR', 'MASTER_PORT', 'WORLD_SIZE', 'RANK', 'LOCAL_RANK', 'NCCL_DEBUG']:
                if var in os.environ:
                    del os.environ[var]
            
            self.distributed_initialized = False
                    
        except Exception as e:
            logger.warning(f"Error during distributed cleanup: {e}")

    def _init_comfyui_models(self, model_info: Dict) -> bool:
        """ç›´æŽ¥ä½¿ç”¨ComfyUIçš„æ¨¡åž‹æ–‡ä»¶åˆå§‹åŒ–"""
        logger.info(f"[GPU {self.gpu_id}] Initializing with ComfyUI models")
        
        try:
            # ç®€åŒ–å¯¼å…¥é€»è¾‘
            import sys
            import os
            
            # èŽ·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
            current_dir = os.path.dirname(os.path.abspath(__file__))
            
            # å¦‚æžœå½“å‰ç›®å½•ä¸åœ¨sys.pathä¸­ï¼Œæ·»åŠ å®ƒ
            if current_dir not in sys.path:
                sys.path.insert(0, current_dir)
            
            # çŽ°åœ¨å°è¯•å¯¼å…¥
            from comfyui_model_wrapper import ComfyUIModelWrapper
            
            # èŽ·å–æ¨¡åž‹è·¯å¾„
            model_path = model_info.get('path', self.model_path)
            
            # èŽ·å–VAEå’ŒCLIPè·¯å¾„ï¼ˆå¦‚æžœæœ‰çš„è¯ï¼‰
            vae_path = None
            clip_paths = []
            
            # å°è¯•è‡ªåŠ¨æŸ¥æ‰¾ç›¸å…³çš„VAEå’ŒCLIP
            if model_path.endswith('.safetensors'):
                model_name = os.path.basename(model_path).replace('.safetensors', '')
                
                # æŸ¥æ‰¾VAE
                try:
                    vae_folder = folder_paths.get_folder_paths("vae")[0]
                    potential_vae = os.path.join(vae_folder, "flux", "ae.safetensors")
                    if os.path.exists(potential_vae):
                        vae_path = potential_vae
                        logger.info(f"[GPU {self.gpu_id}] Found VAE: {vae_path}")
                except Exception as e:
                    logger.warning(f"[GPU {self.gpu_id}] Could not find VAE: {e}")
                
                # æŸ¥æ‰¾CLIP
                try:
                    clip_folder = folder_paths.get_folder_paths("text_encoders")[0]
                    clip_l_path = os.path.join(clip_folder, "flux", "t5xxl_fp16.safetensors")
                    clip_g_path = os.path.join(clip_folder, "flux", "clip_l.safetensors")
                    
                    if os.path.exists(clip_l_path):
                        clip_paths.append(clip_l_path)
                    if os.path.exists(clip_g_path):
                        clip_paths.append(clip_g_path)
                    
                    if clip_paths:
                        logger.info(f"[GPU {self.gpu_id}] Found CLIP: {clip_paths}")
                except Exception as e:
                    logger.warning(f"[GPU {self.gpu_id}] Could not find CLIP: {e}")
            
            # åˆ›å»ºwrapper
            self.comfyui_wrapper = ComfyUIModelWrapper(
                model_path=model_path,
                vae_path=vae_path,
                clip_paths=clip_paths
            )
            
            # åŠ è½½ç»„ä»¶
            if not self.comfyui_wrapper.load_components():
                logger.error(f"[GPU {self.gpu_id}] Failed to load ComfyUI components")
                return False
            
            # ç§»åŠ¨åˆ°GPU
            self.comfyui_wrapper.to(self.device)
            
            # æ ‡è®°ä¸ºComfyUIæ¨¡å¼
            self.model_wrapper = "comfyui_mode"
            self.is_comfyui_mode = True
            
            logger.info(f"[GPU {self.gpu_id}] âœ… ComfyUI models initialized")
            return True
            
        except Exception as e:
            logger.error(f"[GPU {self.gpu_id}] Failed to init ComfyUI models: {e}")
            logger.exception("Init error:")
            return False

    def _run_comfyui_inference(self,
                          conditioning_positive: Any,
                          conditioning_negative: Any,
                          latent_samples: torch.Tensor,
                          num_inference_steps: int,
                          guidance_scale: float,
                          seed: int) -> Optional[torch.Tensor]:
        """ä½¿ç”¨ComfyUIæ¨¡åž‹è¿›è¡ŒæŽ¨ç†"""
        try:
            logger.info(f"[GPU {self.gpu_id}] Starting ComfyUI inference")
            
            # è®¾ç½®éšæœºç§å­
            torch.manual_seed(seed)
            torch.cuda.manual_seed(seed)
            
            # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            latent_samples = latent_samples.to(self.device)
            
            # ä½¿ç”¨ComfyUIçš„é‡‡æ ·æ–¹æ³•
            import comfy.sample
            import comfy.samplers
            
            # åˆ›å»ºå™ªå£°
            noise = torch.randn_like(latent_samples)
            
            # èŽ·å–é‡‡æ ·å™¨
            sampler = comfy.samplers.KSampler(
                self.comfyui_wrapper.unet,
                steps=num_inference_steps,
                device=self.device,
                sampler="euler",
                scheduler="normal",
                denoise=1.0
            )
            
            # æ‰§è¡Œé‡‡æ ·
            samples = sampler.sample(
                noise,
                conditioning_positive,
                conditioning_negative,
                cfg=guidance_scale,
                latent_image=latent_samples,
                force_full_denoise=True
            )
            
            logger.info(f"[GPU {self.gpu_id}] âœ… ComfyUI inference completed")
            return samples
            
        except Exception as e:
            logger.error(f"[GPU {self.gpu_id}] ComfyUI inference failed: {e}")
            logger.exception("Inference error:")
            return None

    
    def run_inference(self, 
                     model_info: Dict,
                     conditioning_positive: Any,
                     conditioning_negative: Any,
                     latent_samples: torch.Tensor,
                     num_inference_steps: int = 20,
                     guidance_scale: float = 8.0,
                     seed: int = 42) -> Optional[torch.Tensor]:
        """è¿è¡ŒæŽ¨ç† - ä½¿ç”¨xDiTçš„åŽŸå§‹æ–¹æ³•"""
        try:
            if not self.is_initialized:
                logger.error(f"Worker on GPU {self.gpu_id} not initialized")
                return None

            # æ£€æŸ¥æ˜¯å¦æ˜¯ComfyUIæ¨¡å¼
            if hasattr(self, 'is_comfyui_mode') and self.is_comfyui_mode:
                logger.info(f"[GPU {self.gpu_id}] Running in ComfyUI mode")
                return self._run_comfyui_inference(
                    conditioning_positive, conditioning_negative,
                    latent_samples, num_inference_steps,
                    guidance_scale, seed
                )
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å¸ƒå¼æŽ¨ç†
            if self.world_size > 1:
                # å¤šGPUæ¨¡å¼ï¼šç¡®ä¿åˆ†å¸ƒå¼å·²åˆå§‹åŒ–
                if not self.distributed_initialized:
                    logger.error(f"[GPU {self.gpu_id}] Distributed not initialized for multi-GPU inference")
                    return None
                
                # åˆ›å»ºpipelineï¼Œä¼ é€’æ­£ç¡®çš„æ¨¡åž‹è·¯å¾„
                model_path = model_info.get('path', self.model_path)
                
                # ðŸŽ¯ ç®€åŒ–ï¼šç›´æŽ¥åˆ›å»ºxDiT pipeline
                if not self._create_xfuser_pipeline_if_needed(model_path):
                    logger.warning(f"âš ï¸ Pipeline creation failed on GPU {self.gpu_id}")
                    return None
            else:
                # å•GPUæ¨¡å¼ï¼šç›´æŽ¥è¿è¡Œ
                logger.info(f"[GPU {self.gpu_id}] Running single-GPU inference")
            
            logger.info(f"Running inference on GPU {self.gpu_id}: {num_inference_steps} steps")
            start_time = time.time()
            
            # è®¾ç½®éšæœºç§å­
            torch.manual_seed(seed)
            torch.cuda.manual_seed(seed)
            
            # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            latent_samples = latent_samples.to(self.device)
            
            # å¤„ç†conditioning
            prompt_embeds = None
            pooled_prompt_embeds = None
            if conditioning_positive and len(conditioning_positive) > 0:
                if isinstance(conditioning_positive[0], torch.Tensor):
                    prompt_embeds = conditioning_positive[0].to(self.device)
                    if len(conditioning_positive) > 1:
                        pooled_prompt_embeds = conditioning_positive[1].to(self.device)
            
            negative_prompt_embeds = None
            negative_pooled_prompt_embeds = None
            if conditioning_negative and len(conditioning_negative) > 0:
                if isinstance(conditioning_negative[0], torch.Tensor):
                    negative_prompt_embeds = conditioning_negative[0].to(self.device)
                    if len(conditioning_negative) > 1:
                        negative_pooled_prompt_embeds = conditioning_negative[1].to(self.device)
            
            # å¦‚æžœæ˜¯å•GPUæˆ–åˆ†å¸ƒå¼å¤±è´¥ï¼Œè¿”å›žNoneè§¦å‘fallback
            if self.world_size == 1 or not self.distributed_initialized:
                logger.info(f"[GPU {self.gpu_id}] Returning None to trigger ComfyUI fallback")
                return None
            
            # ðŸ”§ æ£€æŸ¥æ¨¡åž‹åŒ…è£…å™¨çŠ¶æ€
            if self.model_wrapper is None:
                logger.warning(f"[GPU {self.gpu_id}] Model wrapper not ready, triggering fallback")
                return None
            
            # åˆ›å»ºæŽ¨ç†é…ç½®
            model_path = model_info.get('path', self.model_path)
            xfuser_args = xFuserArgs(
                model=model_path,
                height=latent_samples.shape[2] * 8,
                width=latent_samples.shape[3] * 8,
                num_inference_steps=num_inference_steps,
                guidance_scale=guidance_scale,
                output_type="latent",
                tensor_parallel_degree=self.world_size
            )
            
            engine_config = xfuser_args.create_config()
            logger.info(f"[GPU {self.gpu_id}] Config created: steps={num_inference_steps}, CFG={guidance_scale}")
            
            # è¿è¡ŒæŽ¨ç†
            try:
                with torch.inference_mode():
                    result = self.model_wrapper(
                        prompt_embeds=prompt_embeds,
                        pooled_prompt_embeds=pooled_prompt_embeds,
                        negative_prompt_embeds=negative_prompt_embeds,
                        negative_pooled_prompt_embeds=negative_pooled_prompt_embeds,
                        height=latent_samples.shape[2] * 8,
                        width=latent_samples.shape[3] * 8,
                        num_inference_steps=num_inference_steps,
                        guidance_scale=guidance_scale,
                        generator=torch.Generator(device=self.device).manual_seed(seed),
                        output_type="latent",
                        latents=latent_samples,
                        engine_config=engine_config
                    )
                
                # æå–ç»“æžœ
                if hasattr(result, 'images'):
                    result_latents = result.images
                elif hasattr(result, 'latents'):
                    result_latents = result.latents
                else:
                    result_latents = result
                
                # ç¡®ä¿ç»“æžœåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                result_latents = result_latents.to(self.device)
                
                end_time = time.time()
                logger.info(f"âœ… Inference completed on GPU {self.gpu_id} in {end_time - start_time:.2f}s")
                
                return result_latents
                
            except Exception as e:
                logger.error(f"Inference failed on GPU {self.gpu_id}: {e}")
                logger.exception("Inference traceback:")
                return None
                
        except Exception as e:
            logger.error(f"Error during inference on GPU {self.gpu_id}: {e}")
            logger.exception("Full traceback:")
            return None
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†æ¨¡åž‹
            if self.model_wrapper is not None:
                del self.model_wrapper
                self.model_wrapper = None
            
            # æ¸…ç†åˆ†å¸ƒå¼çŽ¯å¢ƒ
            self._cleanup_distributed()
            
            # æ¸…ç†CUDAç¼“å­˜
            torch.cuda.empty_cache()
            
            self.is_initialized = False
            logger.info(f"âœ… Worker on GPU {self.gpu_id} cleaned up")
            
        except Exception as e:
            logger.error(f"Error during cleanup on GPU {self.gpu_id}: {e}")
            logger.exception("Cleanup traceback:")

    def load_model(self, model_path: str, model_type: str = "flux"):
        """åŠ è½½æ¨¡åž‹ï¼Œæ”¯æŒsafetensorså’Œdiffusersæ ¼å¼"""
        try:
            logger.info(f"[GPU {self.gpu_id}] Loading model: {model_path}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ComfyUIæ ¼å¼ï¼ˆsafetensorsï¼‰
            if model_path.endswith('.safetensors'):
                logger.info(f"[GPU {self.gpu_id}] Detected ComfyUI format, using native loading")
                
                # ä½¿ç”¨ComfyUIæ¨¡å¼
                model_info = {
                    'path': model_path,
                    'type': model_type
                }
                
                if self._init_comfyui_models(model_info):
                    logger.info(f"[GPU {self.gpu_id}] âœ… ComfyUI mode activated")
                    return "comfyui_mode"
                else:
                    logger.warning(f"[GPU {self.gpu_id}] ComfyUI mode failed, using deferred loading")
                    self.model_wrapper = "deferred_loading"
                    return "deferred_loading"
                        
            elif os.path.isdir(model_path):
                # Diffusersæ ¼å¼ç›®å½• - ç›´æŽ¥ä½¿ç”¨åŽŸæœ‰é€»è¾‘
                logger.info(f"[GPU {self.gpu_id}] Detected diffusers format")
                
                # åˆå§‹åŒ–engine_configï¼ˆå¦‚æžœè¿˜æ²¡æœ‰çš„è¯ï¼‰
                if not hasattr(self, 'engine_config'):
                    from xfuser import xFuserArgs
                    xfuser_args = xFuserArgs(
                        model=model_path,
                        height=1024,
                        width=1024,
                        num_inference_steps=20,
                        guidance_scale=3.5,
                        output_type="latent",
                        tensor_parallel_degree=self.world_size,
                        use_ray=True,
                        ray_world_size=self.world_size
                    )
                    self.engine_config = xfuser_args.create_config()
                
                from xfuser import xFuserFluxPipeline
                from diffusers import FluxPipeline
                import torch
                
                pipeline = FluxPipeline.from_pretrained(
                    model_path,
                    torch_dtype=torch.bfloat16,
                    device_map=None,
                    low_cpu_mem_usage=True
                )
                
                self.model_wrapper = xFuserFluxPipeline(pipeline, self.engine_config)
                logger.info(f"[GPU {self.gpu_id}] âœ… Diffusers model loaded successfully")
                
                return "success"
            else:
                logger.warning(f"[GPU {self.gpu_id}] Unknown model format: {model_path}")
                self.model_wrapper = "deferred_loading"
                return "deferred_loading"
                
        except Exception as e:
            logger.error(f"[GPU {self.gpu_id}] Model loading failed: {e}")
            logger.exception("Full traceback:")
            
            # æœ€ç»ˆfallback
            self.model_wrapper = "deferred_loading"
            return "deferred_loading"

# Non-Ray fallback worker for when Ray is not available
class XDiTWorkerFallback:
    """Fallback worker when Ray is not available"""
    
    def __init__(self, gpu_id: int, model_path: str, strategy: str = "Hybrid"):
        self.gpu_id = gpu_id
        self.model_path = model_path
        self.strategy = strategy
        self.model_wrapper = None
        self.is_initialized = False
        
        logger.info(f"Initializing fallback worker on GPU {gpu_id}")
    
    def initialize(self) -> bool:
        """Initialize the fallback worker"""
        try:
            # è®¾ç½®GPUè®¾å¤‡
            if torch.cuda.is_available():
                torch.cuda.set_device(self.gpu_id)
            
            logger.info(f"Fallback worker on GPU {self.gpu_id} ready")
            
            self.is_initialized = True
            logger.info(f"âœ… Fallback worker on GPU {self.gpu_id} initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize fallback worker on GPU {self.gpu_id}: {e}")
            logger.exception("Full traceback:")
            return False
    
    def get_gpu_info(self) -> Dict[str, Any]:
        """Get GPU information"""
        try:
            if not torch.cuda.is_available():
                return {"gpu_id": self.gpu_id, "error": "CUDA not available"}
                
            props = torch.cuda.get_device_properties(self.gpu_id)
            memory_total = props.total_memory / (1024**3)
            memory_reserved = torch.cuda.memory_reserved(self.gpu_id) / (1024**3)
            memory_allocated = torch.cuda.memory_allocated(self.gpu_id) / (1024**3)
            
            return {
                "gpu_id": self.gpu_id,
                "name": props.name,
                "memory_total_gb": memory_total,
                "memory_reserved_gb": memory_reserved,
                "memory_allocated_gb": memory_allocated,
                "memory_free_gb": memory_total - memory_reserved,
                "compute_capability": f"{props.major}.{props.minor}",
                "is_initialized": self.is_initialized
            }
        except Exception as e:
            logger.error(f"Error getting GPU info for GPU {self.gpu_id}: {e}")
            return {"gpu_id": self.gpu_id, "error": str(e)}
    
    def wrap_model_for_xdit(self, model_state_dict: Dict, model_config: Dict) -> bool:
        """Wrap model with xDiT (fallback version)"""
        try:
            logger.info(f"Wrapping model with fallback method on GPU {self.gpu_id}")
            
            # åœ¨æ²¡æœ‰xDiTçš„æƒ…å†µä¸‹ï¼Œç®€å•åœ°å‡†å¤‡å¥½æŽ¥å—æ¨¡åž‹
            self.model_wrapper = "fallback_placeholder"
            
            logger.info(f"âœ… Model ready on GPU {self.gpu_id} (fallback mode)")
            return True
            
        except Exception as e:
            logger.error(f"Failed to wrap model on GPU {self.gpu_id}: {e}")
            return False
    
    def run_inference(self, 
                     model_info: Dict,  # æ”¹ä¸ºè½»é‡çº§çš„æ¨¡åž‹ä¿¡æ¯
                     conditioning_positive: Any,
                     conditioning_negative: Any,
                     latent_samples: torch.Tensor,
                     num_inference_steps: int = 20,
                     guidance_scale: float = 8.0,
                     seed: int = 42) -> Optional[torch.Tensor]:
        """Run inference (fallback version)"""
        try:
            if not self.is_initialized:
                logger.error(f"Fallback worker on GPU {self.gpu_id} not initialized")
                return None
            
            logger.info(f"Running fallback inference on GPU {self.gpu_id}")
            logger.info(f"Model info: {model_info.get('type', 'unknown')}, Latent shape: {latent_samples.shape}")
            start_time = time.time()
            
            # è®¾ç½®éšæœºç§å­
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(seed)
            
            # ðŸ”§ ä¼˜åŒ–ï¼šç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„GPUä¸Š
            device = f"cuda:{self.gpu_id}" if torch.cuda.is_available() else "cpu"
            if latent_samples.device != torch.device(device):
                latent_samples = latent_samples.to(device)
            
            # ðŸ”§ ä¿®å¤Fluxæ¨¡åž‹é€šé“æ•°é—®é¢˜
            # Fluxæ¨¡åž‹ä½¿ç”¨16é€šé“latent spaceï¼Œå¦‚æžœè¾“å…¥æ˜¯4é€šé“ï¼Œéœ€è¦è¿›è¡Œè½¬æ¢
            if latent_samples.shape[1] == 4 and model_info.get('type', '').lower() == 'flux':
                logger.info(f"Converting 4-channel to 16-channel latent for Flux model")
                # ç®€å•çš„é€šé“æ‰©å±•ç­–ç•¥ï¼ˆå®žé™…çš„xDiTä¼šæœ‰æ›´å¤æ‚çš„å¤„ç†ï¼‰
                # æ–¹æ³•1ï¼šé‡å¤é€šé“ [1,4,H,W] -> [1,16,H,W]
                expanded_latents = latent_samples.repeat(1, 4, 1, 1)
                # æ–¹æ³•2ï¼šä¹Ÿå¯ä»¥ç”¨é›¶å¡«å……
                # expanded_latents = torch.cat([latent_samples, torch.zeros_like(latent_samples).repeat(1, 3, 1, 1)], dim=1)
                latent_samples = expanded_latents
                logger.info(f"Latent shape converted to: {latent_samples.shape}")
            
            # åœ¨fallbackæ¨¡å¼ä¸‹ï¼Œåªæ˜¯è¿”å›žåŽŸå§‹latents
            # å®žé™…ä½¿ç”¨ä¸­ä¼šå›žé€€åˆ°ComfyUIçš„æ ‡å‡†é‡‡æ ·
            # result_latents = latent_samples.clone()
            
            # TODO: fallbackæ¨¡å¼ä¹Ÿè¿”å›žNoneï¼Œè®©ç³»ç»Ÿä½¿ç”¨æ ‡å‡†ComfyUIé‡‡æ ·
            logger.info(f"âš ï¸ Fallback worker returning None to trigger standard ComfyUI sampling")
            return None
            
            end_time = time.time()
            logger.info(f"âœ… Fallback inference completed on GPU {self.gpu_id} in {end_time - start_time:.2f}s")
            
            # return result_latents
                
        except Exception as e:
            logger.error(f"Error during fallback inference on GPU {self.gpu_id}: {e}")
            logger.exception("Full traceback:")
            return None
    
    def cleanup(self):
        """Clean up resources"""
        try:
            if self.model_wrapper is not None:
                del self.model_wrapper
                self.model_wrapper = None
            
            self.is_initialized = False
            
            # Clear CUDA cache
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info(f"âœ… Fallback worker on GPU {self.gpu_id} cleaned up")
            
        except Exception as e:
            logger.error(f"Error during cleanup on GPU {self.gpu_id}: {e}") 