#!/usr/bin/env python3
"""
å°†FLUX safetensorsè½¬æ¢ä¸ºdiffusersæ ¼å¼ï¼Œå¯ç”¨å¤šGPUåŠ é€Ÿ
"""

import os
import sys
import torch
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def convert_flux_safetensors_to_diffusers(safetensors_path: str, output_dir: str):
    """
    å°†FLUX safetensorsæ–‡ä»¶è½¬æ¢ä¸ºdiffusersæ ¼å¼
    """
    try:
        logger.info(f"ğŸ”„ å¼€å§‹è½¬æ¢: {safetensors_path} -> {output_dir}")
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(safetensors_path):
            raise FileNotFoundError(f"Safetensorsæ–‡ä»¶ä¸å­˜åœ¨: {safetensors_path}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        from diffusers import FluxPipeline
        
        # æ–¹æ³•1: å°è¯•ä»HuggingFaceä¸‹è½½å®Œæ•´æ¨¡å‹ï¼Œç„¶åæ›¿æ¢transformeræƒé‡
        logger.info("ğŸ“¥ ä¸‹è½½åŸºç¡€FLUXæ¨¡å‹ç»„ä»¶...")
        
        try:
            # ä¸‹è½½å®Œæ•´çš„FLUX.1-devæ¨¡å‹
            pipeline = FluxPipeline.from_pretrained(
                "black-forest-labs/FLUX.1-dev",
                torch_dtype=torch.bfloat16,
                device_map=None,
                low_cpu_mem_usage=True
            )
            
            logger.info("âœ… åŸºç¡€æ¨¡å‹ä¸‹è½½å®Œæˆ")
            
            # åŠ è½½è‡ªå®šä¹‰çš„transformeræƒé‡
            logger.info("ğŸ”„ åŠ è½½è‡ªå®šä¹‰transformeræƒé‡...")
            
            import safetensors.torch
            custom_weights = safetensors.torch.load_file(safetensors_path)
            
            # è¿‡æ»¤å‡ºtransformerç›¸å…³çš„æƒé‡
            transformer_weights = {}
            for key, value in custom_weights.items():
                if any(prefix in key for prefix in ['double_blocks', 'single_blocks', 'img_in', 'txt_in', 'final_layer']):
                    transformer_weights[key] = value
            
            logger.info(f"æ‰¾åˆ° {len(transformer_weights)} ä¸ªtransformeræƒé‡")
            
            # æ›¿æ¢transformeræƒé‡
            pipeline.transformer.load_state_dict(transformer_weights, strict=False)
            logger.info("âœ… Transformeræƒé‡æ›¿æ¢å®Œæˆ")
            
            # ä¿å­˜ä¸ºdiffusersæ ¼å¼
            logger.info(f"ğŸ’¾ ä¿å­˜åˆ°: {output_dir}")
            pipeline.save_pretrained(output_dir)
            
            logger.info("ğŸ‰ è½¬æ¢å®Œæˆ!")
            logger.info(f"âœ… ç°åœ¨å¯ä»¥åœ¨XDiTUNetLoaderä¸­é€‰æ‹©ç›®å½•: {output_dir}")
            
            return True
            
        except Exception as download_error:
            logger.error(f"ä»HuggingFaceä¸‹è½½å¤±è´¥: {download_error}")
            
            # æ–¹æ³•2: åˆ›å»ºæœ€å°çš„diffusersç»“æ„
            logger.info("ğŸ”„ å°è¯•åˆ›å»ºæœ€å°diffusersç»“æ„...")
            return create_minimal_diffusers_structure(safetensors_path, output_dir)
            
    except Exception as e:
        logger.error(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        logger.exception("è¯¦ç»†é”™è¯¯:")
        return False

def create_minimal_diffusers_structure(safetensors_path: str, output_dir: str):
    """
    åˆ›å»ºæœ€å°çš„diffusersç›®å½•ç»“æ„
    """
    try:
        logger.info("ğŸ—ï¸ åˆ›å»ºæœ€å°diffusersç»“æ„...")
        
        # å¤åˆ¶safetensorsæ–‡ä»¶
        import shutil
        shutil.copy2(safetensors_path, os.path.join(output_dir, "diffusion_pytorch_model.safetensors"))
        
        # åˆ›å»ºåŸºæœ¬çš„model_index.json
        model_index = {
            "_class_name": "FluxPipeline",
            "_diffusers_version": "0.21.0",
            "scheduler": ["diffusers", "FlowMatchEulerDiscreteScheduler"],
            "text_encoder": ["transformers", "CLIPTextModel"],
            "text_encoder_2": ["transformers", "T5EncoderModel"],
            "tokenizer": ["transformers", "CLIPTokenizer"],
            "tokenizer_2": ["transformers", "T5Tokenizer"],
            "transformer": ["diffusers", "FluxTransformer2DModel"],
            "vae": ["diffusers", "AutoencoderKL"]
        }
        
        import json
        with open(os.path.join(output_dir, "model_index.json"), "w") as f:
            json.dump(model_index, f, indent=2)
        
        # åˆ›å»ºtransformeré…ç½®
        transformer_config = {
            "_class_name": "FluxTransformer2DModel",
            "_diffusers_version": "0.21.0",
            "guidance_embeds": False,
            "in_channels": 64,
            "joint_attention_dim": 4096,
            "num_attention_heads": 24,
            "num_layers": 19,
            "num_single_layers": 38,
            "pooled_projection_dim": 768,
            "vec_in_dim": 768,
            "axes_dim": [16, 56, 56],
            "theta": 10000,
            "use_bias": True,
            "torch_dtype": "float16"
        }
        
        transformer_dir = os.path.join(output_dir, "transformer")
        os.makedirs(transformer_dir, exist_ok=True)
        
        with open(os.path.join(transformer_dir, "config.json"), "w") as f:
            json.dump(transformer_config, f, indent=2)
        
        # ç§»åŠ¨safetensorsåˆ°transformerç›®å½•
        shutil.move(
            os.path.join(output_dir, "diffusion_pytorch_model.safetensors"),
            os.path.join(transformer_dir, "diffusion_pytorch_model.safetensors")
        )
        
        logger.info("âœ… æœ€å°diffusersç»“æ„åˆ›å»ºå®Œæˆ")
        logger.info("âš ï¸ æ³¨æ„: æ­¤ç»“æ„å¯èƒ½éœ€è¦é¢å¤–çš„ç»„ä»¶æ‰èƒ½å®Œå…¨å·¥ä½œ")
        
        return True
        
    except Exception as e:
        logger.error(f"åˆ›å»ºæœ€å°ç»“æ„å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ FLUX Safetensors to Diffusers è½¬æ¢å·¥å…·")
    print("=" * 50)
    
    # é»˜è®¤è·¯å¾„
    default_input = "/home/shuzuan/prj/ComfyUI-xDit/models/unet/flux/flux1-dev.safetensors"
    default_output = "/home/shuzuan/prj/ComfyUI-xDit/models/unet/flux/flux1-dev-diffusers"
    
    print(f"è¾“å…¥æ–‡ä»¶: {default_input}")
    print(f"è¾“å‡ºç›®å½•: {default_output}")
    print()
    
    if input("æ˜¯å¦ä½¿ç”¨é»˜è®¤è·¯å¾„? (y/n): ").lower() != 'y':
        safetensors_path = input("è¯·è¾“å…¥safetensorsæ–‡ä»¶è·¯å¾„: ")
        output_dir = input("è¯·è¾“å…¥è¾“å‡ºç›®å½•è·¯å¾„: ")
    else:
        safetensors_path = default_input
        output_dir = default_output
    
    print(f"\nğŸ”„ å¼€å§‹è½¬æ¢...")
    
    success = convert_flux_safetensors_to_diffusers(safetensors_path, output_dir)
    
    if success:
        print("\nğŸ‰ è½¬æ¢æˆåŠŸ!")
        print(f"âœ… è¾“å‡ºç›®å½•: {output_dir}")
        print("\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
        print("1. åœ¨ComfyUIä¸­ä½¿ç”¨XDiTUNetLoaderèŠ‚ç‚¹")
        print(f"2. é€‰æ‹©ç›®å½•: flux1-dev-diffusers")
        print("3. å¯ç”¨å¤šGPUåŠ é€Ÿ")
        print("4. äº«å—8GPUå¹¶è¡Œæ¨ç†!")
    else:
        print("\nâŒ è½¬æ¢å¤±è´¥")
        print("è¯·æ£€æŸ¥é”™è¯¯æ—¥å¿—å¹¶é‡è¯•")

if __name__ == "__main__":
    main() 