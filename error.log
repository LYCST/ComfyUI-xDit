Checkpoint files will always be loaded safely.
Total VRAM 24210 MB, total RAM 257688 MB
pytorch version: 2.5.1+cu124
Set vram state to: NORMAL_VRAM
Device: cuda:0 NVIDIA GeForce RTX 4090 : cudaMallocAsync
Using pytorch attention
Python version: 3.11.13 (main, Jun  5 2025, 13:12:00) [GCC 11.2.0]
ComfyUI version: 0.3.41
ComfyUI frontend version: 1.22.2
[Prompt Server] web root: /home/shuzuan/miniconda3/envs/comfyui-xdit/lib/python3.11/site-packages/comfyui_frontend_package/static
/home/shuzuan/miniconda3/envs/comfyui-xdit/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
âœ… xDiT framework loaded successfully
âœ… Ray framework loaded successfully
ðŸš€ ComfyUI xDiT Multi-GPU Plugin v1.0.0 loaded successfully!
   ðŸ“‹ Drop-in replacements for standard ComfyUI nodes:
      â€¢ XDiTCheckpointLoader -> CheckpointLoaderSimple
      â€¢ XDiTUNetLoader -> UNetLoader
      â€¢ XDiTVAELoader -> VAELoader
      â€¢ XDiTCLIPLoader -> CLIPLoader
      â€¢ XDiTDualCLIPLoader -> DualCLIPLoader
      â€¢ XDiTKSampler -> KSampler
   âœ… Multi-GPU acceleration enabled
   ðŸ“Š Available parallel strategies: PipeFusion, USP, Hybrid, Tensor, CFG
   ðŸŽ¯ Ray-based distributed computing enabled
   ðŸ“ˆ Available scheduling strategies: round_robin, least_loaded, weighted_round_robin, adaptive
   ðŸ’¡ Usage: Simply replace standard nodes with xDiT versions for automatic multi-GPU acceleration

Import times for custom nodes:
   0.0 seconds: /home/shuzuan/prj/ComfyUI-xDit/custom_nodes/websocket_image_save.py
   0.7 seconds: /home/shuzuan/prj/ComfyUI-xDit/custom_nodes/comfyui_xdit_multigpu

Context impl SQLiteImpl.
Will assume non-transactional DDL.
No target revision found.
Starting server

To see the GUI go to: http://0.0.0.0:12411
