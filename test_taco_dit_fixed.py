#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„TACO-DiTèŠ‚ç‚¹
"""

import os
import sys
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_taco_dit_import():
    """æµ‹è¯•TACO-DiTæ¨¡å—å¯¼å…¥"""
    try:
        # æ£€æŸ¥torch
        import torch
        logger.info("âœ“ PyTorch available")
        
        # æ£€æŸ¥TACO-DiTæ¨¡å—
        sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
        from comfy.taco_dit import (
            TACODiTConfig,
            TACODiTConfigManager,
            TACODiTDistributedManager,
            TACODiTModelPatcher,
            TACODiTExecutionEngine
        )
        logger.info("âœ“ TACO-DiT modules imported successfully")
        
        # æµ‹è¯•é…ç½®
        config = TACODiTConfig(enabled=True, auto_detect=True)
        logger.info(f"âœ“ TACO-DiT config created: {config}")
        
        return True
        
    except ImportError as e:
        logger.error(f"âœ— Import error: {e}")
        return False
    except Exception as e:
        logger.error(f"âœ— Unexpected error: {e}")
        return False

def test_comfyui_integration():
    """æµ‹è¯•ComfyUIé›†æˆ"""
    try:
        # æ£€æŸ¥ComfyUIèŠ‚ç‚¹
        import nodes
        from nodes import common_ksampler
        logger.info("âœ“ ComfyUI nodes imported successfully")
        
        # æ£€æŸ¥é‡‡æ ·å™¨
        import comfy.samplers
        logger.info("âœ“ ComfyUI samplers imported successfully")
        
        return True
        
    except ImportError as e:
        logger.error(f"âœ— ComfyUI import error: {e}")
        return False
    except Exception as e:
        logger.error(f"âœ— ComfyUI integration error: {e}")
        return False

def test_gpu_availability():
    """æµ‹è¯•GPUå¯ç”¨æ€§"""
    try:
        import torch
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            logger.info(f"âœ“ CUDA available with {gpu_count} GPUs")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                logger.info(f"  GPU {i}: {gpu_name}")
            
            return True
        else:
            logger.warning("âš  CUDA not available, using CPU")
            return True
            
    except Exception as e:
        logger.error(f"âœ— GPU test error: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("="*50)
    logger.info("TACO-DiT Fixed Nodes Test")
    logger.info("="*50)
    
    tests = [
        ("TACO-DiT Import", test_taco_dit_import),
        ("ComfyUI Integration", test_comfyui_integration),
        ("GPU Availability", test_gpu_availability),
    ]
    
    results = []
    for test_name, test_func in tests:
        logger.info(f"\nRunning {test_name}...")
        try:
            result = test_func()
            results.append((test_name, result))
            if result:
                logger.info(f"âœ“ {test_name} passed")
            else:
                logger.error(f"âœ— {test_name} failed")
        except Exception as e:
            logger.error(f"âœ— {test_name} error: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    logger.info("\n" + "="*50)
    logger.info("Test Summary:")
    logger.info("="*50)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        logger.info(f"{test_name}: {status}")
    
    logger.info(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        logger.info("ğŸ‰ All tests passed! TACO-DiT Fixed Nodes are ready to use.")
    else:
        logger.error("âŒ Some tests failed. Please check the errors above.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 